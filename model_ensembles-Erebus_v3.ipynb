{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will implement stacking ensembles models for online shoppers dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code and Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our code of dataset preprocessing is saved in the same folder with this report in descion_tree.py. The data set is also at the same location called \"online_shoppers_intention.csv\". In order to perform stacking. Besides the packages from skearn such as model_selection and accuracy_score, we also used joblib which provides lightweight pipelining in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Desicion_Tree import *\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is preprocessed by calling functions from the external py file before being used for training and testing. x, y are extracted as features and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame_os = read_data_return_frame(\"online_shoppers_intention.csv\")\n",
    "\n",
    "x, y, class_names, feature_names = preprocess_df(data_frame_os)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, a test size of 0.25 and a random state of 21 are set. This is determined by examing different params pairs and comparing the final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size = 0.25, random_state = 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, four pretrained models are loaded to persist to disk transparently and to avoid running reduplicated tasks. dtr, nb, nn, knn were generated using joblib.dump function, representing Decision Tree classifier, Categorical NB classifier, MLP classifier and K Neighbors classifier. All these four models are trained models from group members individual session(only 1 out of 3 classifiers of Bayesian was selected as example). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = joblib.load(\"model/dtr.joblib\")\n",
    "nb = joblib.load(\"model/nb.joblib\")\n",
    "nn = joblib.load(\"model/mlp.joblib\")\n",
    "knn = joblib.load(\"model/knn.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the voting mechanism by using the VotingClassifier of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('dtr', dtr), ('knn', knn), ('nb', nb), ('nn', nn)], voting='hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this voting classifier we need to provide an id for each classifier and the classifiers themselves, and a voting parameter which can be set to hard or soft. If this is set to ‘hard’, it uses the predicted class labels for a majority rule voting, if this is set to ‘soft’, it predicts the class label based on the argmax of the sums of the predicted probabilities.\n",
    "\n",
    "We then fit the voting classifier.(Module CEGE0004 Week-06 Lecture Slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dtr',\n",
       "                              DecisionTreeClassifier(min_samples_leaf=5,\n",
       "                                                     min_samples_split=5)),\n",
       "                             ('knn',\n",
       "                              KNeighborsClassifier(metric='cosine',\n",
       "                                                   n_neighbors=1)),\n",
       "                             ('nb', CategoricalNB(alpha=100)),\n",
       "                             ('nn',\n",
       "                              MLPClassifier(activation='tanh',\n",
       "                                            hidden_layer_sizes=(50, 50),\n",
       "                                            max_iter=1000))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to fit each classifier independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in (dtr, nb, nn, knn):\n",
    "    clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "\ttrain: 0.9089434411160376\n",
      "\ttest: 0.7885176775867662\n",
      "CategoricalNB\n",
      "\ttrain: 0.8458959662593274\n",
      "\ttest: 0.843658773921505\n",
      "MLPClassifier\n",
      "\ttrain: 0.8456796798961825\n",
      "\ttest: 0.843658773921505\n",
      "KNeighborsClassifier\n",
      "\ttrain: 0.9998918568184276\n",
      "\ttest: 0.7606227700291923\n",
      "VotingClassifier\n",
      "\ttrain: 0.8460041094408998\n",
      "\ttest: 0.8439831333117094\n"
     ]
    }
   ],
   "source": [
    "for clf in (dtr, nb, nn, knn,  voting_clf):\n",
    "    print(clf.__class__.__name__)\n",
    "    y_train_pred = clf.predict(x_train)\n",
    "    print('\\ttrain:', accuracy_score(y_train, y_train_pred))\n",
    "    y_test_pred = clf.predict(x_test)\n",
    "    print('\\ttest:', accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking Classifier of Voting Classifier reports 84.4% on Test data which is higher than every other type of classifiers. CategoricalNB and MLPClassifier have the same test accuracy on this dataset, which is only 0.03% lower than Voting Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lipani, A. (2021) UCL (University College London)Module CEGE0004 Week-05 Practical Material  \n",
    "Joblib: running Python functions as pipeline jobs, joblib. https://joblib.readthedocs.io/en/latest/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
